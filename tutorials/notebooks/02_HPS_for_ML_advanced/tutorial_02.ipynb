{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc07e2ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "    \n",
    "By design asyncio does not allow nested event loops. Jupyter is using Tornado which already starts an event loop. Therefore the following patch is required to run this tutorial.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4b2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /Users/romainegele/opt/anaconda3/envs/dhtfp/lib/python3.8/site-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b29a6a",
   "metadata": {},
   "source": [
    "# Hyperparameter Search for Machine Learning (Advanced)\n",
    "\n",
    "In this tutorial, we will show how to treat a learning method as a hyperparameter in the hyperparameter search. We will consider [Random Forest (RF)](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifier and [Gradient Boosting (GB)](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) classifier methods in [Scikit-Learn](https://scikit-learn.org/stable/) for the Airlines data set. Each of these methods have its own set of hyperparameters and some common parameters. We model them using ConfigSpace a python package to express conditional hyperparameters and more.\n",
    "\n",
    "Create a mapping to record the classification algorithms of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b5ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "CLASSIFIERS = {\n",
    "    \"RandomForest\": RandomForestClassifier,\n",
    "    \"GradientBoosting\": GradientBoostingClassifier,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b325396",
   "metadata": {},
   "source": [
    "Create a baseline code to test the accuracy of the default configuration for both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00027653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Accuracy on Training: 0.879\n",
      "Accuracy on Validation: 0.620\n",
      "Accuracy on Testing: 0.620\n",
      "\n",
      "GradientBoosting\n",
      "Accuracy on Training: 0.649\n",
      "Accuracy on Validation: 0.648\n",
      "Accuracy on Testing: 0.649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deephyper.benchmark.datasets import airlines as dataset\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "rs_clf = check_random_state(42)\n",
    "rs_data = check_random_state(42)\n",
    "\n",
    "ratio_test = 0.33\n",
    "ratio_valid = (1 - ratio_test) * 0.33\n",
    "\n",
    "train, valid, test, _ = dataset.load_data(\n",
    "    random_state=rs_data,\n",
    "    test_size=ratio_test,\n",
    "    valid_size=ratio_valid,\n",
    "    categoricals_to_integers=True,\n",
    ")\n",
    "\n",
    "for clf_name, clf_class in CLASSIFIERS.items():\n",
    "    print(clf_name)\n",
    "\n",
    "    clf = clf_class(random_state=rs_clf)\n",
    "\n",
    "    clf.fit(*train)\n",
    "\n",
    "    acc_train = clf.score(*train)\n",
    "    acc_valid = clf.score(*valid)\n",
    "    acc_test = clf.score(*test)\n",
    "\n",
    "    print(f\"Accuracy on Training: {acc_train:.3f}\")\n",
    "    print(f\"Accuracy on Validation: {acc_valid:.3f}\")\n",
    "    print(f\"Accuracy on Testing: {acc_test:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b501b3",
   "metadata": {},
   "source": [
    "The accuracy values show that the RandomForest classifier with default hyperparameters results in overfitting and thus poor generalization (high accuracy on training data but not on the validation and test data). On the contrary GradientBoosting does not show any sign of overfitting and has a better accuracy on the validation and testing set, which shows a better generalization than RandomForest.\n",
    "\n",
    "Next, we optimize the hyperparameters, where we seek to find the right classifier and its corresponding hyperparameters to improve the accuracy on the vaidation and test data. Create a `load_data` function to load and return training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb93095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With subsampling\n",
      "X_train shape: (10000, 7)\n",
      "y_train shape: (10000,)\n",
      "X_valid shape: (119258, 7)\n",
      "y_valid shape: (119258,)\n",
      "\n",
      "Without subsampling\n",
      "X_train shape: (242128, 7)\n",
      "y_train shape: (242128,)\n",
      "X_valid shape: (119258, 7)\n",
      "y_valid shape: (119258,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def load_data(verbose=0, subsample=True):\n",
    "\n",
    "    # In this case passing a random state is critical to make sure\n",
    "    # that the same data are loaded all the time and that the test set\n",
    "    # is not mixed with either the training or validation set.\n",
    "    # It is important to not avoid setting a global seed for safety reasons.\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "\n",
    "    # Proportion of the test set on the full dataset\n",
    "    ratio_test = 0.33\n",
    "\n",
    "    # Proportion of the valid set on \"dataset \\ test set\"\n",
    "    # here we want the test and validation set to have same number of elements\n",
    "    ratio_valid = (1 - ratio_test) * 0.33\n",
    "\n",
    "    # The 3rd result is ignored with \"_\" because it corresponds to the test set\n",
    "    # which is not interesting for us now.\n",
    "    (X_train, y_train), (X_valid, y_valid), _, _ = dataset.load_data(\n",
    "        random_state=random_state,\n",
    "        test_size=ratio_test,\n",
    "        valid_size=ratio_valid,\n",
    "        categoricals_to_integers=True,\n",
    "    )\n",
    "\n",
    "    # Uncomment the next line if you want to sub-sample the training data to speed-up\n",
    "    # the search, \"n_samples\" controls the size of the new training data\n",
    "    if subsample:\n",
    "        X_train, y_train = resample(X_train, y_train, n_samples=int(1e4))\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"X_train shape: {np.shape(X_train)}\")\n",
    "        print(f\"y_train shape: {np.shape(y_train)}\")\n",
    "        print(f\"X_valid shape: {np.shape(X_valid)}\")\n",
    "        print(f\"y_valid shape: {np.shape(y_valid)}\")\n",
    "    return (X_train, y_train), (X_valid, y_valid)\n",
    "\n",
    "print(\"With subsampling\")\n",
    "_ = load_data(verbose=1)\n",
    "print(\"\\nWithout subsampling\")\n",
    "_ = load_data(verbose=1, subsample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ba367",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Tip</b> \n",
    "    \n",
    "Subsampling with `X_train, y_train = resample(X_train, y_train, n_samples=int(1e4))` can be useful if you want to speed-up your search. By subsampling the training time will reduce.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Create a `run` function to train and evaluate a given hyperparameter configuration. This function has to return a scalar value (typically, validation accuracy), which will be maximized by the search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2f3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephyper.problem import filter_parameters\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "def run(config: dict) -> float:\n",
    "\n",
    "    config[\"random_state\"] = check_random_state(42)\n",
    "\n",
    "    (X_train, y_train), (X_valid, y_valid) = load_data()\n",
    "\n",
    "    clf_class = CLASSIFIERS[config[\"classifier\"]]\n",
    "\n",
    "    # keep parameters possible for the current classifier\n",
    "    config[\"n_jobs\"] = 4\n",
    "    clf_params = filter_parameters(clf_class, config)\n",
    "\n",
    "    try:  # good practice to manage the fail value yourself...\n",
    "        clf = clf_class(**clf_params)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        fit_is_complete = True\n",
    "    except:\n",
    "        fit_is_complete = False\n",
    "\n",
    "    if fit_is_complete:\n",
    "        y_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_pred)\n",
    "    else:\n",
    "        acc = -1.0\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c11701",
   "metadata": {},
   "source": [
    "Create the `HpProblem` to define the search space of hyperparameters for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e39b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    classifier, Type: Categorical, Choices: {RandomForest, GradientBoosting}, Default: RandomForest\n",
      "    criterion, Type: Categorical, Choices: {friedman_mse, mse, gini, entropy}, Default: gini\n",
      "    learning_rate, Type: UniformFloat, Range: [0.01, 1.0], Default: 0.505\n",
      "    loss, Type: Categorical, Choices: {deviance, exponential}, Default: deviance\n",
      "    max_depth, Type: UniformInteger, Range: [1, 50], Default: 26\n",
      "    min_samples_leaf, Type: UniformInteger, Range: [1, 10], Default: 6\n",
      "    min_samples_split, Type: UniformInteger, Range: [2, 10], Default: 6\n",
      "    n_estimators, Type: UniformInteger, Range: [1, 1000], Default: 32, on log-scale\n",
      "    subsample, Type: UniformFloat, Range: [0.01, 1.0], Default: 0.505\n",
      "  Conditions:\n",
      "    learning_rate | classifier == 'GradientBoosting'\n",
      "    loss | classifier == 'GradientBoosting'\n",
      "    subsample | classifier == 'GradientBoosting'\n",
      "  Forbidden Clauses:\n",
      "    (Forbidden: classifier == 'RandomForest' && Forbidden: criterion in {'friedman_mse', 'mse'})\n",
      "    (Forbidden: classifier == 'GradientBoosting' && Forbidden: criterion in {'entropy', 'gini'})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ConfigSpace as cs\n",
    "from deephyper.problem import HpProblem\n",
    "\n",
    "\n",
    "problem = HpProblem(seed=42)\n",
    "\n",
    "#! Default value are very important when adding conditional and forbidden clauses\n",
    "#! Otherwise the creation of the problem can fail if the default configuration is not\n",
    "#! Acceptable\n",
    "classifier = problem.add_hyperparameter(\n",
    "    name=\"classifier\",\n",
    "    value=[\"RandomForest\", \"GradientBoosting\"],\n",
    "    default_value=\"RandomForest\",\n",
    ")\n",
    "\n",
    "# For both\n",
    "problem.add_hyperparameter(name=\"n_estimators\", value=(1, 1000, \"log-uniform\"))\n",
    "problem.add_hyperparameter(name=\"max_depth\", value=(1, 50))\n",
    "problem.add_hyperparameter(\n",
    "    name=\"min_samples_split\", value=(2, 10),\n",
    ")\n",
    "problem.add_hyperparameter(name=\"min_samples_leaf\", value=(1, 10))\n",
    "criterion = problem.add_hyperparameter(\n",
    "    name=\"criterion\",\n",
    "    value=[\"friedman_mse\", \"mse\", \"gini\", \"entropy\"],\n",
    "    default_value=\"gini\",\n",
    ")\n",
    "\n",
    "# GradientBoosting\n",
    "loss = problem.add_hyperparameter(name=\"loss\", value=[\"deviance\", \"exponential\"])\n",
    "learning_rate = problem.add_hyperparameter(name=\"learning_rate\", value=(0.01, 1.0))\n",
    "subsample = problem.add_hyperparameter(name=\"subsample\", value=(0.01, 1.0))\n",
    "\n",
    "gradient_boosting_hp = [loss, learning_rate, subsample]\n",
    "for hp_i in gradient_boosting_hp:\n",
    "    problem.add_condition(cs.EqualsCondition(hp_i, classifier, \"GradientBoosting\"))\n",
    "\n",
    "forbidden_criterion_rf = cs.ForbiddenAndConjunction(\n",
    "    cs.ForbiddenEqualsClause(classifier, \"RandomForest\"),\n",
    "    cs.ForbiddenInClause(criterion, [\"friedman_mse\", \"mse\"]),\n",
    ")\n",
    "problem.add_forbidden_clause(forbidden_criterion_rf)\n",
    "\n",
    "forbidden_criterion_gb = cs.ForbiddenAndConjunction(\n",
    "    cs.ForbiddenEqualsClause(classifier, \"GradientBoosting\"),\n",
    "    cs.ForbiddenInClause(criterion, [\"gini\", \"entropy\"]),\n",
    ")\n",
    "problem.add_forbidden_clause(forbidden_criterion_gb)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452fe5b",
   "metadata": {},
   "source": [
    "Create an `Evaluator` object using the `ray` backend to distribute the evaluation of the run-function defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197f723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-16 10:53:21,544\tINFO services.py:1267 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers:  2\n"
     ]
    }
   ],
   "source": [
    "from deephyper.evaluator.evaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator.create(run, \n",
    "                 method=\"ray\", \n",
    "                 method_kwargs={\n",
    "                     \"address\": None, \n",
    "                     \"num_cpus\": 2,\n",
    "                     \"num_cpus_per_task\": 1\n",
    "                 })\n",
    "\n",
    "print(\"Number of workers: \", evaluator.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6cd751",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Tip</b> \n",
    "    \n",
    "You can open the ray-dashboard at an address like <a>http://127.0.0.1:port</a> in a browser to monitor the CPU usage of the execution.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Finally, you can define a Bayesian optimization search called `AMBS` (for Asynchronous Model-Based Search) and link to it the defined `problem` and `evaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e09062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephyper.search.hps import AMBS\n",
    "\n",
    "search = AMBS(problem, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0892e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.search(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b4096",
   "metadata": {},
   "source": [
    "Once the search is over, a file named `results.csv` is saved in the current directory. The same dataframe is returned by the `search.search(...)` call. It contains the hyperparameters configurations evaluated during the search and their corresponding `objective` value (i.e, validation accuracy), `duration` of computation and time of computation with `elapsed_sec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e7aed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>subsample</th>\n",
       "      <th>id</th>\n",
       "      <th>objective</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>mse</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098640</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.992143</td>\n",
       "      <td>2</td>\n",
       "      <td>0.556206</td>\n",
       "      <td>6.641314</td>\n",
       "      <td>3.544160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633869</td>\n",
       "      <td>6.782724</td>\n",
       "      <td>3.685584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>entropy</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.601637</td>\n",
       "      <td>7.824726</td>\n",
       "      <td>0.797032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>entropy</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.623220</td>\n",
       "      <td>8.840261</td>\n",
       "      <td>0.773575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0.650378</td>\n",
       "      <td>deviance</td>\n",
       "      <td>0.483268</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583374</td>\n",
       "      <td>9.364809</td>\n",
       "      <td>2.582544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.619640</td>\n",
       "      <td>10.388878</td>\n",
       "      <td>0.753619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.584791</td>\n",
       "      <td>11.444127</td>\n",
       "      <td>0.783659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.629241</td>\n",
       "      <td>12.763110</td>\n",
       "      <td>3.591230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.641232</td>\n",
       "      <td>14.624261</td>\n",
       "      <td>2.900479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.624369</td>\n",
       "      <td>16.076699</td>\n",
       "      <td>1.172646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.641408</td>\n",
       "      <td>16.766948</td>\n",
       "      <td>3.727033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.352140</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.667373</td>\n",
       "      <td>13</td>\n",
       "      <td>0.601947</td>\n",
       "      <td>18.497667</td>\n",
       "      <td>1.440734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.638288</td>\n",
       "      <td>20.461339</td>\n",
       "      <td>4.090252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.642431</td>\n",
       "      <td>27.824640</td>\n",
       "      <td>7.086693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>591</td>\n",
       "      <td>0.496904</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.204430</td>\n",
       "      <td>14</td>\n",
       "      <td>0.578997</td>\n",
       "      <td>28.100584</td>\n",
       "      <td>9.312014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.641743</td>\n",
       "      <td>34.863481</td>\n",
       "      <td>6.763509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0.640896</td>\n",
       "      <td>35.152189</td>\n",
       "      <td>6.710557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>0.615481</td>\n",
       "      <td>36.040813</td>\n",
       "      <td>0.889197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0.637668</td>\n",
       "      <td>38.648042</td>\n",
       "      <td>2.335480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0.638431</td>\n",
       "      <td>42.264201</td>\n",
       "      <td>6.818357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>0.636159</td>\n",
       "      <td>45.013730</td>\n",
       "      <td>2.434960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>0.636251</td>\n",
       "      <td>45.605843</td>\n",
       "      <td>6.650002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>0.642875</td>\n",
       "      <td>47.402385</td>\n",
       "      <td>1.482760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>entropy</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.639278</td>\n",
       "      <td>49.171334</td>\n",
       "      <td>1.482675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>entropy</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>0.639949</td>\n",
       "      <td>51.355909</td>\n",
       "      <td>1.878485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>mse</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>347</td>\n",
       "      <td>0.033787</td>\n",
       "      <td>deviance</td>\n",
       "      <td>0.668515</td>\n",
       "      <td>27</td>\n",
       "      <td>0.611280</td>\n",
       "      <td>73.207729</td>\n",
       "      <td>21.512272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>470</td>\n",
       "      <td>0.088609</td>\n",
       "      <td>deviance</td>\n",
       "      <td>0.445832</td>\n",
       "      <td>23</td>\n",
       "      <td>0.602224</td>\n",
       "      <td>73.597104</td>\n",
       "      <td>28.252060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>75.134161</td>\n",
       "      <td>1.202841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>0.225728</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.762401</td>\n",
       "      <td>30</td>\n",
       "      <td>0.608177</td>\n",
       "      <td>78.718433</td>\n",
       "      <td>3.305998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gini</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0.637114</td>\n",
       "      <td>80.183159</td>\n",
       "      <td>1.184163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          classifier     criterion  max_depth  min_samples_leaf  \\\n",
       "0   GradientBoosting           mse         45                 8   \n",
       "1       RandomForest          gini         16                 9   \n",
       "2       RandomForest       entropy         44                 8   \n",
       "3       RandomForest       entropy         22                10   \n",
       "4   GradientBoosting           mse          6                 9   \n",
       "5       RandomForest          gini          3                 5   \n",
       "6       RandomForest          gini         31                 9   \n",
       "7       RandomForest          gini         32                 1   \n",
       "8       RandomForest          gini         14                 8   \n",
       "9       RandomForest       entropy          3                 5   \n",
       "10      RandomForest          gini         18                 8   \n",
       "11  GradientBoosting  friedman_mse         23                 7   \n",
       "12      RandomForest       entropy         13                10   \n",
       "13      RandomForest          gini         50                 8   \n",
       "14  GradientBoosting  friedman_mse          9                 8   \n",
       "15      RandomForest          gini         48                 9   \n",
       "16      RandomForest          gini         34                 8   \n",
       "17      RandomForest          gini         47                 4   \n",
       "18      RandomForest          gini         15                 8   \n",
       "19      RandomForest          gini         14                 9   \n",
       "20      RandomForest          gini         46                 8   \n",
       "21      RandomForest          gini         47                 7   \n",
       "22      RandomForest          gini         48                 9   \n",
       "23      RandomForest       entropy         40                 8   \n",
       "24      RandomForest       entropy         41                10   \n",
       "25  GradientBoosting           mse         26                 8   \n",
       "26  GradientBoosting  friedman_mse         38                 5   \n",
       "27      RandomForest          gini         16                10   \n",
       "28  GradientBoosting  friedman_mse         29                10   \n",
       "29      RandomForest          gini         36                 8   \n",
       "\n",
       "    min_samples_split  n_estimators  learning_rate         loss  subsample  \\\n",
       "0                   7             1       0.098640  exponential   0.992143   \n",
       "1                   5            12            NaN          NaN        NaN   \n",
       "2                   6             4            NaN          NaN        NaN   \n",
       "3                   2             7            NaN          NaN        NaN   \n",
       "4                   3           129       0.650378     deviance   0.483268   \n",
       "5                   3             2            NaN          NaN        NaN   \n",
       "6                   4             1            NaN          NaN        NaN   \n",
       "7                   4           355            NaN          NaN        NaN   \n",
       "8                   5           317            NaN          NaN        NaN   \n",
       "9                   5            92            NaN          NaN        NaN   \n",
       "10                  7           414            NaN          NaN        NaN   \n",
       "11                  9            10       0.352140  exponential   0.667373   \n",
       "12                  5           519            NaN          NaN        NaN   \n",
       "13                  5           942            NaN          NaN        NaN   \n",
       "14                  8           591       0.496904  exponential   0.204430   \n",
       "15                  6           737            NaN          NaN        NaN   \n",
       "16                  4           707            NaN          NaN        NaN   \n",
       "17                  9            10            NaN          NaN        NaN   \n",
       "18                  3           192            NaN          NaN        NaN   \n",
       "19                  9           826            NaN          NaN        NaN   \n",
       "20                  5           179            NaN          NaN        NaN   \n",
       "21                  9           699            NaN          NaN        NaN   \n",
       "22                  2            99            NaN          NaN        NaN   \n",
       "23                  6            93            NaN          NaN        NaN   \n",
       "24                  7           150            NaN          NaN        NaN   \n",
       "25                  8           347       0.033787     deviance   0.668515   \n",
       "26                  5           470       0.088609     deviance   0.445832   \n",
       "27                  8            59            NaN          NaN        NaN   \n",
       "28                  7            39       0.225728  exponential   0.762401   \n",
       "29                  8            60            NaN          NaN        NaN   \n",
       "\n",
       "    id  objective  elapsed_sec   duration  \n",
       "0    2   0.556206     6.641314   3.544160  \n",
       "1    1   0.633869     6.782724   3.685584  \n",
       "2    4   0.601637     7.824726   0.797032  \n",
       "3    5   0.623220     8.840261   0.773575  \n",
       "4    3   0.583374     9.364809   2.582544  \n",
       "5    7   0.619640    10.388878   0.753619  \n",
       "6    8   0.584791    11.444127   0.783659  \n",
       "7    6   0.629241    12.763110   3.591230  \n",
       "8    9   0.641232    14.624261   2.900479  \n",
       "9   11   0.624369    16.076699   1.172646  \n",
       "10  10   0.641408    16.766948   3.727033  \n",
       "11  13   0.601947    18.497667   1.440734  \n",
       "12  12   0.638288    20.461339   4.090252  \n",
       "13  15   0.642431    27.824640   7.086693  \n",
       "14  14   0.578997    28.100584   9.312014  \n",
       "15  16   0.641743    34.863481   6.763509  \n",
       "16  17   0.640896    35.152189   6.710557  \n",
       "17  18   0.615481    36.040813   0.889197  \n",
       "18  20   0.637668    38.648042   2.335480  \n",
       "19  19   0.638431    42.264201   6.818357  \n",
       "20  22   0.636159    45.013730   2.434960  \n",
       "21  21   0.636251    45.605843   6.650002  \n",
       "22  24   0.642875    47.402385   1.482760  \n",
       "23  25   0.639278    49.171334   1.482675  \n",
       "24  26   0.639949    51.355909   1.878485  \n",
       "25  27   0.611280    73.207729  21.512272  \n",
       "26  23   0.602224    73.597104  28.252060  \n",
       "27  29   0.638649    75.134161   1.202841  \n",
       "28  30   0.608177    78.718433   3.305998  \n",
       "29  31   0.637114    80.183159   1.184163  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d51e46",
   "metadata": {},
   "source": [
    "The `deephyper-analytics` command line is a way of analyzing this type of file. For example, we want to output the best configuration we can use the `topk` functionnality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7da7c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'0':\r\n",
      "  classifier: RandomForest\r\n",
      "  criterion: gini\r\n",
      "  duration: 1.4827599525\r\n",
      "  elapsed_sec: 47.402384758\r\n",
      "  id: 24\r\n",
      "  learning_rate: null\r\n",
      "  loss: null\r\n",
      "  max_depth: 48\r\n",
      "  min_samples_leaf: 9\r\n",
      "  min_samples_split: 2\r\n",
      "  n_estimators: 99\r\n",
      "  objective: 0.6428751111\r\n",
      "  subsample: null\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!deephyper-analytics topk results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba059c1",
   "metadata": {},
   "source": [
    "Let us define a test to evaluate the best configuration on the training, validation and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081b52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config is:\n",
      "{'classifier': 'RandomForest',\n",
      " 'criterion': 'gini',\n",
      " 'id': 24,\n",
      " 'learning_rate': nan,\n",
      " 'loss': nan,\n",
      " 'max_depth': 48,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 99,\n",
      " 'objective': 0.6428751111036576,\n",
      " 'subsample': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training: 0.755\n",
      "Accuracy on Validation: 0.665\n",
      "Accuracy on Testing: 0.664\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "config = results.iloc[results.objective.argmax()][:-2].to_dict()\n",
    "print(\"Best config is:\")\n",
    "pprint(config)\n",
    "\n",
    "config[\"random_state\"] = check_random_state(42)\n",
    "\n",
    "rs_data = check_random_state(42)\n",
    "\n",
    "ratio_test = 0.33\n",
    "ratio_valid = (1 - ratio_test) * 0.33\n",
    "\n",
    "train, valid, test, _ = dataset.load_data(\n",
    "    random_state=rs_data,\n",
    "    test_size=ratio_test,\n",
    "    valid_size=ratio_valid,\n",
    "    categoricals_to_integers=True,\n",
    ")\n",
    "\n",
    "clf_class = CLASSIFIERS[config[\"classifier\"]]\n",
    "config[\"n_jobs\"] = 4\n",
    "clf_params = filter_parameters(clf_class, config)\n",
    "\n",
    "clf = clf_class(**clf_params)\n",
    "\n",
    "clf.fit(*train)\n",
    "\n",
    "acc_train = clf.score(*train)\n",
    "acc_valid = clf.score(*valid)\n",
    "acc_test = clf.score(*test)\n",
    "\n",
    "print(f\"Accuracy on Training: {acc_train:.3f}\")\n",
    "print(f\"Accuracy on Validation: {acc_valid:.3f}\")\n",
    "print(f\"Accuracy on Testing: {acc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307f865",
   "metadata": {},
   "source": [
    "Compared to the default configuration, we can see the accuracy improvement and the reduction of overfitting between the training and  the validation/test data sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
